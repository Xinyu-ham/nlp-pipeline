{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchdata.datapipes.iter import IterableWrapper, S3FileLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = 'data/covid.zip'\n",
    "BUCKET_NAME = 'xy-mp-pipeline'\n",
    "OUTPUT_PATH = 'data/covid-csv'\n",
    "N_SAMPLES = 10201\n",
    "BATCHES = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing and uploading data to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A post claims compulsory vacination violates t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A photo claims that this person is a doctor wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Post about a video claims that it is a protest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All deaths by respiratory failure and pneumoni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dean of the College of Biologists of Euska...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  outcome\n",
       "0  A post claims compulsory vacination violates t...        0\n",
       "1  A photo claims that this person is a doctor wh...        0\n",
       "2  Post about a video claims that it is a protest...        0\n",
       "3  All deaths by respiratory failure and pneumoni...        0\n",
       "4  The dean of the College of Biologists of Euska...        0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_SOURCE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_df(df, batches):\n",
    "    len_positive = len(df[df['outcome'] == 1])\n",
    "    len_negative = len(df[df['outcome'] == 0])\n",
    "\n",
    "    pad_positve = batches - len_positive % batches\n",
    "    pad_negative = batches - len_negative % batches\n",
    "\n",
    "    df = pd.concat([df, df[df['outcome'] == 1].sample(n=pad_positve, replace=True)], axis=0)\n",
    "    df = pd.concat([df, df[df['outcome'] == 1].sample(n=pad_negative, replace=True)], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    positive = df[df['outcome'] == 1]\n",
    "    negative = df[df['outcome'] == 0]\n",
    "\n",
    "    n_pos = len(positive)\n",
    "    n_neg = len(negative)\n",
    "\n",
    "    negative_test = negative.iloc[:int(n_neg * test_size)]\n",
    "    negative_train = negative.iloc[int(n_neg * test_size):]\n",
    "    positive_test = positive.iloc[:int(n_pos * test_size)]\n",
    "    positive_train = positive.iloc[int(n_pos * test_size):]\n",
    "\n",
    "    train_df = pd.concat([positive_train, negative_train])\n",
    "    test_df = pd.concat([positive_test, negative_test])\n",
    "    return train_df, test_df\n",
    " \n",
    "def write_csvs(df, folder, output_path, batches):\n",
    "    if not os.path.exists(output_path + '/' + folder):\n",
    "        os.makedirs(output_path + '/' + folder)\n",
    "\n",
    "    batch_size = len(df) // batches\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        batch.to_csv(f'{output_path}/{folder}/file{i}.csv', index=False)\n",
    "\n",
    "def write_files_to_s3(output_path, bucket_name):\n",
    "    !aws s3 rm --recursive s3://$bucket_name/$output_path\n",
    "    !aws s3 cp --recursive $output_path s3://$bucket_name/$output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1008.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1323.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file0.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1134.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1197.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file126.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1449.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1071.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1512.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1386.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1260.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1575.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1638.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1764.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1701.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file189.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1827.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1890.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file315.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file1953.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file378.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file252.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file504.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file441.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file567.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file63.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file2016.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file630.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file882.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file756.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file945.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file819.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/testing/file693.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file0.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file1275.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file1020.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file1785.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file2040.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file1530.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file2295.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file255.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file2550.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file3825.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file3315.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file3060.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file4080.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file2805.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file4335.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file4590.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file3570.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file5610.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file510.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file5100.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file5355.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file4845.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file5865.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file6120.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file6375.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file6630.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file7650.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file7905.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file6885.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file7395.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file7140.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file765.csv\n",
      "delete: s3://xy-mp-pipeline/data/covid-csv/training/file8160.csv\n",
      "Completed 7.7 KiB/1.1 MiB (14.9 KiB/s) with 66 file(s) remaining\n",
      "Completed 14.9 KiB/1.1 MiB (28.7 KiB/s) with 66 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1386.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1386.csv\n",
      "Completed 14.9 KiB/1.1 MiB (28.7 KiB/s) with 65 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1197.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1197.csv\n",
      "Completed 14.9 KiB/1.1 MiB (28.7 KiB/s) with 64 file(s) remaining\n",
      "Completed 19.2 KiB/1.1 MiB (36.9 KiB/s) with 64 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1512.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1512.csv\n",
      "Completed 19.2 KiB/1.1 MiB (36.9 KiB/s) with 63 file(s) remaining\n",
      "Completed 27.3 KiB/1.1 MiB (52.5 KiB/s) with 63 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1071.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1071.csv\n",
      "Completed 27.3 KiB/1.1 MiB (52.5 KiB/s) with 62 file(s) remaining\n",
      "Completed 31.6 KiB/1.1 MiB (60.0 KiB/s) with 62 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1575.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1575.csv\n",
      "Completed 31.6 KiB/1.1 MiB (60.0 KiB/s) with 61 file(s) remaining\n",
      "Completed 35.9 KiB/1.1 MiB (68.0 KiB/s) with 61 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1449.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1449.csv\n",
      "Completed 35.9 KiB/1.1 MiB (68.0 KiB/s) with 60 file(s) remaining\n",
      "Completed 43.6 KiB/1.1 MiB (82.5 KiB/s) with 60 file(s) remaining\n",
      "Completed 47.9 KiB/1.1 MiB (90.5 KiB/s) with 60 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1638.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1638.csv\n",
      "Completed 47.9 KiB/1.1 MiB (90.5 KiB/s) with 59 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1260.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1260.csv\n",
      "Completed 47.9 KiB/1.1 MiB (90.5 KiB/s) with 58 file(s) remaining\n",
      "Completed 55.8 KiB/1.1 MiB (105.2 KiB/s) with 58 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file126.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file126.csv\n",
      "Completed 55.8 KiB/1.1 MiB (105.2 KiB/s) with 57 file(s) remaining\n",
      "Completed 64.1 KiB/1.1 MiB (118.6 KiB/s) with 57 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1323.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1323.csv\n",
      "Completed 64.1 KiB/1.1 MiB (118.6 KiB/s) with 56 file(s) remaining\n",
      "Completed 68.4 KiB/1.1 MiB (123.7 KiB/s) with 56 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1701.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1701.csv\n",
      "Completed 68.4 KiB/1.1 MiB (123.7 KiB/s) with 55 file(s) remaining\n",
      "Completed 72.7 KiB/1.1 MiB (131.0 KiB/s) with 55 file(s) remaining\n",
      "Completed 81.3 KiB/1.1 MiB (146.2 KiB/s) with 55 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1134.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1134.csv\n",
      "Completed 81.3 KiB/1.1 MiB (146.2 KiB/s) with 54 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1827.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1827.csv\n",
      "Completed 81.3 KiB/1.1 MiB (146.2 KiB/s) with 53 file(s) remaining\n",
      "Completed 85.5 KiB/1.1 MiB (153.3 KiB/s) with 53 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1764.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1764.csv\n",
      "Completed 85.5 KiB/1.1 MiB (153.3 KiB/s) with 52 file(s) remaining\n",
      "Completed 92.7 KiB/1.1 MiB (163.9 KiB/s) with 52 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file252.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file252.csv\n",
      "Completed 92.7 KiB/1.1 MiB (163.9 KiB/s) with 51 file(s) remaining\n",
      "Completed 98.2 KiB/1.1 MiB (173.7 KiB/s) with 51 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1953.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1953.csv\n",
      "Completed 98.2 KiB/1.1 MiB (173.7 KiB/s) with 50 file(s) remaining\n",
      "Completed 101.0 KiB/1.1 MiB (178.0 KiB/s) with 50 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file2016.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file2016.csv\n",
      "Completed 101.0 KiB/1.1 MiB (178.0 KiB/s) with 49 file(s) remaining\n",
      "Completed 105.3 KiB/1.1 MiB (183.6 KiB/s) with 49 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1890.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1890.csv\n",
      "Completed 105.3 KiB/1.1 MiB (183.6 KiB/s) with 48 file(s) remaining\n",
      "Completed 113.8 KiB/1.1 MiB (196.8 KiB/s) with 48 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file315.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file315.csv\n",
      "Completed 113.8 KiB/1.1 MiB (196.8 KiB/s) with 47 file(s) remaining\n",
      "Completed 122.1 KiB/1.1 MiB (207.0 KiB/s) with 47 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file189.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file189.csv\n",
      "Completed 122.1 KiB/1.1 MiB (207.0 KiB/s) with 46 file(s) remaining\n",
      "Completed 129.3 KiB/1.1 MiB (218.4 KiB/s) with 46 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file504.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file504.csv\n",
      "Completed 129.3 KiB/1.1 MiB (218.4 KiB/s) with 45 file(s) remaining\n",
      "Completed 136.5 KiB/1.1 MiB (230.3 KiB/s) with 45 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file378.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file378.csv\n",
      "Completed 136.5 KiB/1.1 MiB (230.3 KiB/s) with 44 file(s) remaining\n",
      "Completed 143.4 KiB/1.1 MiB (241.0 KiB/s) with 44 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file441.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file441.csv\n",
      "Completed 143.4 KiB/1.1 MiB (241.0 KiB/s) with 43 file(s) remaining\n",
      "Completed 150.8 KiB/1.1 MiB (251.7 KiB/s) with 43 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file567.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file567.csv\n",
      "Completed 150.8 KiB/1.1 MiB (251.7 KiB/s) with 42 file(s) remaining\n",
      "Completed 157.9 KiB/1.1 MiB (260.9 KiB/s) with 42 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file693.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file693.csv\n",
      "Completed 157.9 KiB/1.1 MiB (260.9 KiB/s) with 41 file(s) remaining\n",
      "Completed 165.3 KiB/1.1 MiB (271.4 KiB/s) with 41 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file756.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file756.csv\n",
      "Completed 165.3 KiB/1.1 MiB (271.4 KiB/s) with 40 file(s) remaining\n",
      "Completed 173.0 KiB/1.1 MiB (279.4 KiB/s) with 40 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file819.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file819.csv\n",
      "Completed 173.0 KiB/1.1 MiB (279.4 KiB/s) with 39 file(s) remaining\n",
      "Completed 179.2 KiB/1.1 MiB (288.4 KiB/s) with 39 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file630.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file630.csv\n",
      "Completed 179.2 KiB/1.1 MiB (288.4 KiB/s) with 38 file(s) remaining\n",
      "Completed 188.3 KiB/1.1 MiB (301.4 KiB/s) with 38 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file882.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file882.csv\n",
      "Completed 188.3 KiB/1.1 MiB (301.4 KiB/s) with 37 file(s) remaining\n",
      "Completed 195.7 KiB/1.1 MiB (313.3 KiB/s) with 37 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file945.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file945.csv\n",
      "Completed 195.7 KiB/1.1 MiB (313.3 KiB/s) with 36 file(s) remaining\n",
      "Completed 203.6 KiB/1.1 MiB (322.8 KiB/s) with 36 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file63.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file63.csv\n",
      "Completed 203.6 KiB/1.1 MiB (322.8 KiB/s) with 35 file(s) remaining\n",
      "Completed 234.9 KiB/1.1 MiB (360.3 KiB/s) with 35 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file1785.csv to s3://xy-mp-pipeline/data/covid-csv/training/file1785.csv\n",
      "Completed 234.9 KiB/1.1 MiB (360.3 KiB/s) with 34 file(s) remaining\n",
      "Completed 266.2 KiB/1.1 MiB (407.7 KiB/s) with 34 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file1275.csv to s3://xy-mp-pipeline/data/covid-csv/training/file1275.csv\n",
      "Completed 266.2 KiB/1.1 MiB (407.7 KiB/s) with 33 file(s) remaining\n",
      "Completed 288.5 KiB/1.1 MiB (436.6 KiB/s) with 33 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file0.csv to s3://xy-mp-pipeline/data/covid-csv/training/file0.csv\n",
      "Completed 288.5 KiB/1.1 MiB (436.6 KiB/s) with 32 file(s) remaining\n",
      "Completed 320.7 KiB/1.1 MiB (481.2 KiB/s) with 32 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file1530.csv to s3://xy-mp-pipeline/data/covid-csv/training/file1530.csv\n",
      "Completed 320.7 KiB/1.1 MiB (481.2 KiB/s) with 31 file(s) remaining\n",
      "Completed 351.2 KiB/1.1 MiB (521.3 KiB/s) with 31 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file2550.csv to s3://xy-mp-pipeline/data/covid-csv/training/file2550.csv\n",
      "Completed 351.2 KiB/1.1 MiB (521.3 KiB/s) with 30 file(s) remaining\n",
      "Completed 382.6 KiB/1.1 MiB (561.3 KiB/s) with 30 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file1020.csv to s3://xy-mp-pipeline/data/covid-csv/training/file1020.csv\n",
      "Completed 382.6 KiB/1.1 MiB (561.3 KiB/s) with 29 file(s) remaining\n",
      "Completed 411.8 KiB/1.1 MiB (599.3 KiB/s) with 29 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file2040.csv to s3://xy-mp-pipeline/data/covid-csv/training/file2040.csv\n",
      "Completed 411.8 KiB/1.1 MiB (599.3 KiB/s) with 28 file(s) remaining\n",
      "Completed 437.0 KiB/1.1 MiB (636.0 KiB/s) with 28 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file255.csv to s3://xy-mp-pipeline/data/covid-csv/training/file255.csv\n",
      "Completed 437.0 KiB/1.1 MiB (636.0 KiB/s) with 27 file(s) remaining\n",
      "Completed 467.8 KiB/1.1 MiB (679.7 KiB/s) with 27 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file2295.csv to s3://xy-mp-pipeline/data/covid-csv/training/file2295.csv\n",
      "Completed 467.8 KiB/1.1 MiB (679.7 KiB/s) with 26 file(s) remaining\n",
      "Completed 497.8 KiB/1.1 MiB (721.3 KiB/s) with 26 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file2805.csv to s3://xy-mp-pipeline/data/covid-csv/training/file2805.csv\n",
      "Completed 497.8 KiB/1.1 MiB (721.3 KiB/s) with 25 file(s) remaining\n",
      "Completed 527.9 KiB/1.1 MiB (759.3 KiB/s) with 25 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file3570.csv to s3://xy-mp-pipeline/data/covid-csv/training/file3570.csv\n",
      "Completed 527.9 KiB/1.1 MiB (759.3 KiB/s) with 24 file(s) remaining\n",
      "Completed 558.1 KiB/1.1 MiB (801.6 KiB/s) with 24 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file3060.csv to s3://xy-mp-pipeline/data/covid-csv/training/file3060.csv\n",
      "Completed 558.1 KiB/1.1 MiB (801.6 KiB/s) with 23 file(s) remaining\n",
      "Completed 565.6 KiB/1.1 MiB (802.1 KiB/s) with 23 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file1008.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file1008.csv\n",
      "Completed 565.6 KiB/1.1 MiB (802.1 KiB/s) with 22 file(s) remaining\n",
      "Completed 597.4 KiB/1.1 MiB (828.9 KiB/s) with 22 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file3825.csv to s3://xy-mp-pipeline/data/covid-csv/training/file3825.csv\n",
      "Completed 597.4 KiB/1.1 MiB (828.9 KiB/s) with 21 file(s) remaining\n",
      "Completed 626.2 KiB/1.1 MiB (859.0 KiB/s) with 21 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file4080.csv to s3://xy-mp-pipeline/data/covid-csv/training/file4080.csv\n",
      "Completed 626.2 KiB/1.1 MiB (859.0 KiB/s) with 20 file(s) remaining\n",
      "Completed 653.9 KiB/1.1 MiB (894.5 KiB/s) with 20 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file4845.csv to s3://xy-mp-pipeline/data/covid-csv/training/file4845.csv\n",
      "Completed 653.9 KiB/1.1 MiB (894.5 KiB/s) with 19 file(s) remaining\n",
      "Completed 683.3 KiB/1.1 MiB (931.0 KiB/s) with 19 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file510.csv to s3://xy-mp-pipeline/data/covid-csv/training/file510.csv\n",
      "Completed 683.3 KiB/1.1 MiB (931.0 KiB/s) with 18 file(s) remaining\n",
      "Completed 712.6 KiB/1.1 MiB (964.3 KiB/s) with 18 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file3315.csv to s3://xy-mp-pipeline/data/covid-csv/training/file3315.csv\n",
      "Completed 712.6 KiB/1.1 MiB (964.3 KiB/s) with 17 file(s) remaining\n",
      "Completed 742.1 KiB/1.1 MiB (987.0 KiB/s) with 17 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file4335.csv to s3://xy-mp-pipeline/data/covid-csv/training/file4335.csv\n",
      "Completed 742.1 KiB/1.1 MiB (987.0 KiB/s) with 16 file(s) remaining\n",
      "Completed 771.8 KiB/1.1 MiB (1.0 MiB/s) with 16 file(s) remaining  \n",
      "upload: data\\covid-csv\\training\\file5100.csv to s3://xy-mp-pipeline/data/covid-csv/training/file5100.csv\n",
      "Completed 771.8 KiB/1.1 MiB (1.0 MiB/s) with 15 file(s) remaining\n",
      "Completed 797.7 KiB/1.1 MiB (1.0 MiB/s) with 15 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file5355.csv to s3://xy-mp-pipeline/data/covid-csv/training/file5355.csv\n",
      "Completed 797.7 KiB/1.1 MiB (1.0 MiB/s) with 14 file(s) remaining\n",
      "Completed 825.5 KiB/1.1 MiB (1.1 MiB/s) with 14 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file4590.csv to s3://xy-mp-pipeline/data/covid-csv/training/file4590.csv\n",
      "Completed 825.5 KiB/1.1 MiB (1.1 MiB/s) with 13 file(s) remaining\n",
      "Completed 850.1 KiB/1.1 MiB (1.1 MiB/s) with 13 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file5610.csv to s3://xy-mp-pipeline/data/covid-csv/training/file5610.csv\n",
      "Completed 850.1 KiB/1.1 MiB (1.1 MiB/s) with 12 file(s) remaining\n",
      "Completed 874.0 KiB/1.1 MiB (1.1 MiB/s) with 12 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file6630.csv to s3://xy-mp-pipeline/data/covid-csv/training/file6630.csv\n",
      "Completed 874.0 KiB/1.1 MiB (1.1 MiB/s) with 11 file(s) remaining\n",
      "Completed 896.1 KiB/1.1 MiB (1.1 MiB/s) with 11 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file6120.csv to s3://xy-mp-pipeline/data/covid-csv/training/file6120.csv\n",
      "Completed 896.1 KiB/1.1 MiB (1.1 MiB/s) with 10 file(s) remaining\n",
      "Completed 920.7 KiB/1.1 MiB (1.1 MiB/s) with 10 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file6375.csv to s3://xy-mp-pipeline/data/covid-csv/training/file6375.csv\n",
      "Completed 920.7 KiB/1.1 MiB (1.1 MiB/s) with 9 file(s) remaining\n",
      "Completed 945.8 KiB/1.1 MiB (1.2 MiB/s) with 9 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file5865.csv to s3://xy-mp-pipeline/data/covid-csv/training/file5865.csv\n",
      "Completed 945.8 KiB/1.1 MiB (1.2 MiB/s) with 8 file(s) remaining\n",
      "Completed 966.5 KiB/1.1 MiB (1.2 MiB/s) with 8 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file7140.csv to s3://xy-mp-pipeline/data/covid-csv/training/file7140.csv\n",
      "Completed 966.5 KiB/1.1 MiB (1.2 MiB/s) with 7 file(s) remaining\n",
      "Completed 987.3 KiB/1.1 MiB (1.2 MiB/s) with 7 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file6885.csv to s3://xy-mp-pipeline/data/covid-csv/training/file6885.csv\n",
      "Completed 987.3 KiB/1.1 MiB (1.2 MiB/s) with 6 file(s) remaining\n",
      "Completed 1017.2 KiB/1.1 MiB (1.2 MiB/s) with 6 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file765.csv to s3://xy-mp-pipeline/data/covid-csv/training/file765.csv\n",
      "Completed 1017.2 KiB/1.1 MiB (1.2 MiB/s) with 5 file(s) remaining\n",
      "Completed 1017.6 KiB/1.1 MiB (1.2 MiB/s) with 5 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file8160.csv to s3://xy-mp-pipeline/data/covid-csv/training/file8160.csv\n",
      "Completed 1017.6 KiB/1.1 MiB (1.2 MiB/s) with 4 file(s) remaining\n",
      "Completed 1.0 MiB/1.1 MiB (1.2 MiB/s) with 4 file(s) remaining   \n",
      "upload: data\\covid-csv\\training\\file7905.csv to s3://xy-mp-pipeline/data/covid-csv/training/file7905.csv\n",
      "Completed 1.0 MiB/1.1 MiB (1.2 MiB/s) with 3 file(s) remaining\n",
      "Completed 1.0 MiB/1.1 MiB (1.3 MiB/s) with 3 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file7395.csv to s3://xy-mp-pipeline/data/covid-csv/training/file7395.csv\n",
      "Completed 1.0 MiB/1.1 MiB (1.3 MiB/s) with 2 file(s) remaining\n",
      "Completed 1.0 MiB/1.1 MiB (1.3 MiB/s) with 2 file(s) remaining\n",
      "upload: data\\covid-csv\\testing\\file0.csv to s3://xy-mp-pipeline/data/covid-csv/testing/file0.csv\n",
      "Completed 1.0 MiB/1.1 MiB (1.3 MiB/s) with 1 file(s) remaining\n",
      "Completed 1.1 MiB/1.1 MiB (1.3 MiB/s) with 1 file(s) remaining\n",
      "upload: data\\covid-csv\\training\\file7650.csv to s3://xy-mp-pipeline/data/covid-csv/training/file7650.csv\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df)\n",
    "train_len, test_len = len(train_df), len(test_df)\n",
    "write_csvs(train_df, 'training', OUTPUT_PATH, BATCHES)\n",
    "write_csvs(test_df, 'testing', OUTPUT_PATH, BATCHES)\n",
    "\n",
    "write_files_to_s3(OUTPUT_PATH, BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8162, 2039)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len, test_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create benchmarking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.datapipes.iter import IterableWrapper, IterDataPipe\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class TextDataset(IterDataPipe):\n",
    "    def __init__(self, s3_urls, tokenizer, length):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.url_wrapper = s3_urls\n",
    "        self.len = length\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _, file in self.url_wrapper.load_files_by_s3():\n",
    "            temp = pd.read_csv(file)\n",
    "            label = torch.from_numpy(temp['outcome'].values)\n",
    "            embedded = [self.tokenizer(t, padding='max_length', max_length=100, truncation=True, return_tensors='pt') for t in temp['headlines']]\n",
    "\n",
    "            input_ids = torch.cat([e['input_ids'] for e in embedded], dim=0)\n",
    "            attention_mask = torch.cat([e['attention_mask'] for e in embedded], dim=0)\n",
    "            yield input_ids, attention_mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class FakeNewsClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "        self.linear = torch.nn.Linear(768, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        return self.sigmoid(linear_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, train_data_url: str, test_data_url: str, train_len: int, test_len:int, epochs: int, lr: float):\n",
    "    # Prepare dataloaders\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    train_s3_url = IterableWrapper([train_data_url]).list_files_by_s3().shuffle().sharding_filter()\n",
    "    test_s3_url = IterableWrapper([test_data_url]).list_files_by_s3().shuffle().sharding_filter()\n",
    "\n",
    "    train_df = TextDataset(train_s3_url, tokenizer, train_len)\n",
    "    test_df = TextDataset(test_s3_url, tokenizer, test_len)\n",
    "\n",
    "    train_loader = DataLoader(train_df, batch_size=1, shuffle=True, collate_fn=lambda x: x)\n",
    "    test_loader = DataLoader(test_df, batch_size=1, shuffle=True, collate_fn=lambda x: x)\n",
    "\n",
    "    # Config device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Config optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = torch.nn.BCELoss()\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        training_acc = 0.0\n",
    "\n",
    "        for data in train_loader:\n",
    "            input_ids, mask, label = data[0]\n",
    "            label = label.unsqueeze(1).to(device)\n",
    "            mask = mask.to(device)\n",
    "            input_ids = input_ids.squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_ids, mask)\n",
    "\n",
    "            loss = loss_function(output, label.float())\n",
    "            training_loss += loss.item()\n",
    "\n",
    "            # get acc of signmoid output\n",
    "            acc = (output[0].round() == label).sum().item()\n",
    "            training_acc += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        validation_loss = 0.0\n",
    "        validation_acc = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                input_ids, mask, label = data[0]\n",
    "                label = label.unsqueeze(1).to(device)\n",
    "                mask = mask.to(device)\n",
    "                input_ids = input_ids.squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_ids, mask)\n",
    "\n",
    "                loss = loss_function(output, label.float())\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                acc = (output[0].round() == label).sum().item()\n",
    "                validation_acc += acc\n",
    "        print(f'Epoch: {epoch+1}/{epochs} | Training loss: {training_loss/len(train_loader):.3f} | Training acc: {training_acc/len(train_loader):.3f} | Validation loss: {validation_loss/len(test_loader):.3f} | Validation acc: {validation_acc/len(test_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 | Training loss: 0.001 | Training acc: 0.922 | Validation loss: 0.004 | Validation acc: 0.954\n",
      "Epoch: 2/5 | Training loss: 0.001 | Training acc: 0.953 | Validation loss: 0.003 | Validation acc: 0.954\n",
      "Epoch: 3/5 | Training loss: 0.001 | Training acc: 0.953 | Validation loss: 0.004 | Validation acc: 0.954\n",
      "Epoch: 4/5 | Training loss: 0.001 | Training acc: 0.953 | Validation loss: 0.004 | Validation acc: 0.954\n",
      "Epoch: 5/5 | Training loss: 0.000 | Training acc: 0.953 | Validation loss: 0.005 | Validation acc: 0.830\n",
      "Model saved to:   assets/model\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = FakeNewsClassifier()\n",
    "LR = 5e-6\n",
    "TRAIN_S3_URL = f's3://{BUCKET_NAME}/{OUTPUT_PATH}/training/'\n",
    "TEST_S3_URL = f's3://{BUCKET_NAME}/{OUTPUT_PATH}/testing/'\n",
    "MODEL_OUTPUT_PATH = 'assets/model'\n",
    "\n",
    "train_model(model, TRAIN_S3_URL, TEST_S3_URL, train_len, test_len, EPOCHS, LR)\n",
    "# same model \n",
    "torch.save(model.state_dict(), MODEL_OUTPUT_PATH + '/baseline.pth')\n",
    "print('Model saved to:  ', MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = df[df['outcome'] == 1].headlines.values\n",
    "tests = [tokenizer(t, padding='max_length', max_length=100, truncation=True, return_tensors='pt') for t in tests]\n",
    "input_ids = torch.cat([e['input_ids'] for e in tests], dim=0)\n",
    "attention_mask = torch.cat([e['attention_mask'] for e in tests], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0365],\n",
       "        [0.0366],\n",
       "        [0.0386],\n",
       "        [0.0505],\n",
       "        [0.0351],\n",
       "        [0.0891],\n",
       "        [0.0552],\n",
       "        [0.0680],\n",
       "        [0.0461],\n",
       "        [0.0467],\n",
       "        [0.6530],\n",
       "        [0.0315],\n",
       "        [0.1040],\n",
       "        [0.0318],\n",
       "        [0.0952],\n",
       "        [0.0628],\n",
       "        [0.0487],\n",
       "        [0.0398],\n",
       "        [0.0303],\n",
       "        [0.0745],\n",
       "        [0.0558],\n",
       "        [0.0318],\n",
       "        [0.0341],\n",
       "        [0.0414],\n",
       "        [0.0325],\n",
       "        [0.0289],\n",
       "        [0.0565],\n",
       "        [0.0258],\n",
       "        [0.0467],\n",
       "        [0.0280],\n",
       "        [0.0202],\n",
       "        [0.1002],\n",
       "        [0.0671],\n",
       "        [0.0407],\n",
       "        [0.0403],\n",
       "        [0.0535],\n",
       "        [0.4472],\n",
       "        [0.0296],\n",
       "        [0.0496],\n",
       "        [0.0241],\n",
       "        [0.0483],\n",
       "        [0.0241],\n",
       "        [0.0352],\n",
       "        [0.0543],\n",
       "        [0.0453],\n",
       "        [0.0360],\n",
       "        [0.0441],\n",
       "        [0.0488],\n",
       "        [0.0294],\n",
       "        [0.0551],\n",
       "        [0.0312],\n",
       "        [0.0489],\n",
       "        [0.1632],\n",
       "        [0.0483],\n",
       "        [0.2091],\n",
       "        [0.0509],\n",
       "        [0.0892],\n",
       "        [0.0351],\n",
       "        [0.1341],\n",
       "        [0.0368],\n",
       "        [0.0386],\n",
       "        [0.0496],\n",
       "        [0.0288],\n",
       "        [0.0404],\n",
       "        [0.0434],\n",
       "        [0.0518],\n",
       "        [0.0516],\n",
       "        [0.0220],\n",
       "        [0.0284],\n",
       "        [0.0846],\n",
       "        [0.0432],\n",
       "        [0.0410],\n",
       "        [0.0374],\n",
       "        [0.0560],\n",
       "        [0.0377],\n",
       "        [0.0740],\n",
       "        [0.0757],\n",
       "        [0.3472],\n",
       "        [0.0410],\n",
       "        [0.0718],\n",
       "        [0.1233],\n",
       "        [0.0247],\n",
       "        [0.0351],\n",
       "        [0.0510],\n",
       "        [0.0635],\n",
       "        [0.0203],\n",
       "        [0.0357],\n",
       "        [0.1455],\n",
       "        [0.0566],\n",
       "        [0.0282],\n",
       "        [0.0398],\n",
       "        [0.0667],\n",
       "        [0.1524],\n",
       "        [0.1118],\n",
       "        [0.4191],\n",
       "        [0.0469],\n",
       "        [0.0416],\n",
       "        [0.0543],\n",
       "        [0.1147],\n",
       "        [0.0980],\n",
       "        [0.1214],\n",
       "        [0.1348],\n",
       "        [0.1243],\n",
       "        [0.0442],\n",
       "        [0.4093],\n",
       "        [0.0607],\n",
       "        [0.0555],\n",
       "        [0.1335],\n",
       "        [0.3376],\n",
       "        [0.0415],\n",
       "        [0.0944],\n",
       "        [0.0700],\n",
       "        [0.0309],\n",
       "        [0.3461],\n",
       "        [0.0231],\n",
       "        [0.0322],\n",
       "        [0.0341],\n",
       "        [0.0916],\n",
       "        [0.0385],\n",
       "        [0.0356],\n",
       "        [0.0660],\n",
       "        [0.5389],\n",
       "        [0.7136],\n",
       "        [0.1908],\n",
       "        [0.6239],\n",
       "        [0.3798],\n",
       "        [0.6788],\n",
       "        [0.7310],\n",
       "        [0.5420],\n",
       "        [0.5251],\n",
       "        [0.6546],\n",
       "        [0.6034],\n",
       "        [0.4644],\n",
       "        [0.6352],\n",
       "        [0.5365],\n",
       "        [0.4571],\n",
       "        [0.5721],\n",
       "        [0.2076],\n",
       "        [0.5568],\n",
       "        [0.3279],\n",
       "        [0.2702],\n",
       "        [0.5707],\n",
       "        [0.5669],\n",
       "        [0.7350],\n",
       "        [0.6333],\n",
       "        [0.6596],\n",
       "        [0.6662],\n",
       "        [0.7366],\n",
       "        [0.6150],\n",
       "        [0.6481],\n",
       "        [0.2101],\n",
       "        [0.5939],\n",
       "        [0.6473],\n",
       "        [0.7760],\n",
       "        [0.5818],\n",
       "        [0.6926],\n",
       "        [0.2640],\n",
       "        [0.7058],\n",
       "        [0.6256],\n",
       "        [0.6643],\n",
       "        [0.5852],\n",
       "        [0.6147],\n",
       "        [0.5275],\n",
       "        [0.1712],\n",
       "        [0.7152],\n",
       "        [0.5949],\n",
       "        [0.7414],\n",
       "        [0.6950],\n",
       "        [0.2163],\n",
       "        [0.6746],\n",
       "        [0.6558],\n",
       "        [0.7104],\n",
       "        [0.5673],\n",
       "        [0.7259],\n",
       "        [0.2676],\n",
       "        [0.5738],\n",
       "        [0.7254],\n",
       "        [0.6888],\n",
       "        [0.5936],\n",
       "        [0.2208],\n",
       "        [0.6924],\n",
       "        [0.6750],\n",
       "        [0.6199],\n",
       "        [0.6802],\n",
       "        [0.2946],\n",
       "        [0.5564],\n",
       "        [0.5705],\n",
       "        [0.6496],\n",
       "        [0.5818],\n",
       "        [0.6274],\n",
       "        [0.6029],\n",
       "        [0.6681],\n",
       "        [0.6423],\n",
       "        [0.5439],\n",
       "        [0.5357],\n",
       "        [0.6325],\n",
       "        [0.1969],\n",
       "        [0.6781],\n",
       "        [0.6552],\n",
       "        [0.5630],\n",
       "        [0.6915],\n",
       "        [0.3041],\n",
       "        [0.6351],\n",
       "        [0.5604],\n",
       "        [0.6652],\n",
       "        [0.6267],\n",
       "        [0.7037],\n",
       "        [0.7784],\n",
       "        [0.7000],\n",
       "        [0.7693],\n",
       "        [0.7686],\n",
       "        [0.6270],\n",
       "        [0.4546],\n",
       "        [0.5299],\n",
       "        [0.3247],\n",
       "        [0.6906],\n",
       "        [0.7152],\n",
       "        [0.4917],\n",
       "        [0.6576],\n",
       "        [0.5651],\n",
       "        [0.4333],\n",
       "        [0.6986],\n",
       "        [0.5725],\n",
       "        [0.6842],\n",
       "        [0.6464],\n",
       "        [0.5211],\n",
       "        [0.4123],\n",
       "        [0.5134],\n",
       "        [0.5862],\n",
       "        [0.6282],\n",
       "        [0.6264],\n",
       "        [0.7006],\n",
       "        [0.6532],\n",
       "        [0.6300],\n",
       "        [0.6390],\n",
       "        [0.6984],\n",
       "        [0.6357],\n",
       "        [0.7347],\n",
       "        [0.6610],\n",
       "        [0.7007],\n",
       "        [0.7081],\n",
       "        [0.5879],\n",
       "        [0.5197],\n",
       "        [0.6175],\n",
       "        [0.6451],\n",
       "        [0.6888],\n",
       "        [0.6028],\n",
       "        [0.6389],\n",
       "        [0.6744],\n",
       "        [0.6475],\n",
       "        [0.3270],\n",
       "        [0.6367],\n",
       "        [0.1583],\n",
       "        [0.7007],\n",
       "        [0.2103],\n",
       "        [0.5850],\n",
       "        [0.6106],\n",
       "        [0.6112],\n",
       "        [0.6072],\n",
       "        [0.6361],\n",
       "        [0.5755],\n",
       "        [0.6682],\n",
       "        [0.6341],\n",
       "        [0.6013],\n",
       "        [0.2674],\n",
       "        [0.2563],\n",
       "        [0.2987],\n",
       "        [0.6404],\n",
       "        [0.0823],\n",
       "        [0.6094],\n",
       "        [0.7055],\n",
       "        [0.7211],\n",
       "        [0.6154],\n",
       "        [0.5855],\n",
       "        [0.6376],\n",
       "        [0.6099],\n",
       "        [0.6563],\n",
       "        [0.6134],\n",
       "        [0.6599],\n",
       "        [0.5157],\n",
       "        [0.6271],\n",
       "        [0.6734],\n",
       "        [0.7190],\n",
       "        [0.6860],\n",
       "        [0.5448],\n",
       "        [0.6409],\n",
       "        [0.5732],\n",
       "        [0.5725],\n",
       "        [0.6395],\n",
       "        [0.5949],\n",
       "        [0.5302],\n",
       "        [0.6281],\n",
       "        [0.6809],\n",
       "        [0.1835],\n",
       "        [0.1638],\n",
       "        [0.5491],\n",
       "        [0.6891],\n",
       "        [0.5809],\n",
       "        [0.6282],\n",
       "        [0.5923],\n",
       "        [0.6399],\n",
       "        [0.5242],\n",
       "        [0.6784],\n",
       "        [0.6207],\n",
       "        [0.6981],\n",
       "        [0.6130],\n",
       "        [0.6671],\n",
       "        [0.6299],\n",
       "        [0.2362],\n",
       "        [0.6361],\n",
       "        [0.5919],\n",
       "        [0.6192],\n",
       "        [0.7022],\n",
       "        [0.5357],\n",
       "        [0.4989],\n",
       "        [0.4557],\n",
       "        [0.2463],\n",
       "        [0.6774],\n",
       "        [0.5665],\n",
       "        [0.6332],\n",
       "        [0.7279],\n",
       "        [0.5258],\n",
       "        [0.5645],\n",
       "        [0.5437],\n",
       "        [0.5749],\n",
       "        [0.6207],\n",
       "        [0.5877],\n",
       "        [0.6678],\n",
       "        [0.7364],\n",
       "        [0.5281],\n",
       "        [0.6393],\n",
       "        [0.5161],\n",
       "        [0.6840],\n",
       "        [0.5325],\n",
       "        [0.7677],\n",
       "        [0.2842],\n",
       "        [0.4878],\n",
       "        [0.6200],\n",
       "        [0.6614],\n",
       "        [0.5440],\n",
       "        [0.4509],\n",
       "        [0.7384],\n",
       "        [0.0799],\n",
       "        [0.3618],\n",
       "        [0.5572],\n",
       "        [0.4335],\n",
       "        [0.4017],\n",
       "        [0.6490],\n",
       "        [0.6386],\n",
       "        [0.5749],\n",
       "        [0.3713],\n",
       "        [0.5999],\n",
       "        [0.2954],\n",
       "        [0.6495],\n",
       "        [0.3086],\n",
       "        [0.6767],\n",
       "        [0.6416],\n",
       "        [0.6703],\n",
       "        [0.6403],\n",
       "        [0.6624],\n",
       "        [0.6908],\n",
       "        [0.6169],\n",
       "        [0.6041],\n",
       "        [0.6927],\n",
       "        [0.5821],\n",
       "        [0.5752],\n",
       "        [0.5420],\n",
       "        [0.6193],\n",
       "        [0.6180],\n",
       "        [0.6676],\n",
       "        [0.5781],\n",
       "        [0.5931],\n",
       "        [0.6356],\n",
       "        [0.5774],\n",
       "        [0.6179],\n",
       "        [0.4495],\n",
       "        [0.6141],\n",
       "        [0.5464],\n",
       "        [0.5763],\n",
       "        [0.5053],\n",
       "        [0.5409],\n",
       "        [0.5684],\n",
       "        [0.6205],\n",
       "        [0.7723],\n",
       "        [0.6447],\n",
       "        [0.2327],\n",
       "        [0.6827],\n",
       "        [0.5706],\n",
       "        [0.7061],\n",
       "        [0.6594],\n",
       "        [0.5902],\n",
       "        [0.5286],\n",
       "        [0.6317],\n",
       "        [0.6247],\n",
       "        [0.4631],\n",
       "        [0.5754],\n",
       "        [0.5656],\n",
       "        [0.6382],\n",
       "        [0.6058],\n",
       "        [0.4308],\n",
       "        [0.5511],\n",
       "        [0.6580],\n",
       "        [0.6533],\n",
       "        [0.5606],\n",
       "        [0.2170],\n",
       "        [0.5756],\n",
       "        [0.4158],\n",
       "        [0.6514],\n",
       "        [0.6311],\n",
       "        [0.5595],\n",
       "        [0.6904],\n",
       "        [0.5078],\n",
       "        [0.6566],\n",
       "        [0.5766],\n",
       "        [0.6719],\n",
       "        [0.4128],\n",
       "        [0.7143],\n",
       "        [0.8012],\n",
       "        [0.5450],\n",
       "        [0.4615],\n",
       "        [0.5988],\n",
       "        [0.6592],\n",
       "        [0.5703],\n",
       "        [0.5749],\n",
       "        [0.6260],\n",
       "        [0.5964],\n",
       "        [0.6699],\n",
       "        [0.5556],\n",
       "        [0.5767],\n",
       "        [0.6701],\n",
       "        [0.6396],\n",
       "        [0.5721],\n",
       "        [0.6344],\n",
       "        [0.5654],\n",
       "        [0.5542],\n",
       "        [0.5736],\n",
       "        [0.4991],\n",
       "        [0.5809],\n",
       "        [0.4425],\n",
       "        [0.3484],\n",
       "        [0.5029],\n",
       "        [0.7259],\n",
       "        [0.6460],\n",
       "        [0.7079],\n",
       "        [0.5985],\n",
       "        [0.2223],\n",
       "        [0.6575],\n",
       "        [0.7261],\n",
       "        [0.0265],\n",
       "        [0.0259],\n",
       "        [0.0347],\n",
       "        [0.0376],\n",
       "        [0.0432],\n",
       "        [0.0239],\n",
       "        [0.0273],\n",
       "        [0.0307],\n",
       "        [0.0251],\n",
       "        [0.0486],\n",
       "        [0.1072],\n",
       "        [0.0318],\n",
       "        [0.4327],\n",
       "        [0.1603],\n",
       "        [0.1168],\n",
       "        [0.0544],\n",
       "        [0.1162],\n",
       "        [0.0259],\n",
       "        [0.1635],\n",
       "        [0.1135],\n",
       "        [0.0624],\n",
       "        [0.0250],\n",
       "        [0.0222],\n",
       "        [0.0363],\n",
       "        [0.0317],\n",
       "        [0.0282]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
