{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Baseline Model\n",
    "Baseline model is an important step in any machine learning project. It gives data scientists the illusion of progress, imaging that empty dopamine surge when they see some number goes up for a test set that is in no way an indication of the model's performance with real world data after deployment.\n",
    "\n",
    "Without this baseline, how data scientists suppose to tell the world what kind of progress they have made? How can they tell their boss that they have done something useful? How can they tell their friends that they are not wasting their time? **How can they tell their parents that they are not a failure**? (I swear to god this entire paragraph is generated by Copilot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchdata.datapipes.iter import IterableWrapper, IterDataPipe\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import logging\n",
    "\n",
    "\n",
    "import boto3, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember in the previous chapter I was like \"*oh saving the metadata of our dataset is going to be useful*\" and you were totally doubting me? Well, here we are, using importing it from our bucket again. I hope you feel proud of yourself :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()\n",
    "\n",
    "BUCKET_NAME = 'xy-mp-pipeline'\n",
    "METADATA_KEY = 'data/covid-csv-metadata.json'\n",
    "bucket = boto3.resource('s3').Bucket(BUCKET_NAME)\n",
    "metadata = json.loads(bucket.Object(METADATA_KEY).get()['Body'].read())\n",
    "input_schema = metadata['schema']['input_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, just gonna casually define more constants.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUTPUT_PATH = 'data/covid-csv'\n",
    "N_SAMPLES = metadata['dataset_size']\n",
    "TRAIN_FILES = N_SAMPLES * 4 // 5 // 16 + 1\n",
    "TEST_FILES = N_SAMPLES // 5 // 16 + 1\n",
    "BATCH_SIZE = metadata['batch_size']\n",
    "TRAIN_S3_URL = f's3://{BUCKET_NAME}/{OUTPUT_PATH}/training/'\n",
    "TEST_S3_URL = f's3://{BUCKET_NAME}/{OUTPUT_PATH}/testing/'\n",
    "TEST_DATASET_SIZE = metadata['test_size']\n",
    "TRAIN_DATASET_SIZE = metadata['train_size']\n",
    "MODEL_OUTPUT_PATH = 'assets/model'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data pipe\n",
    "So a data pipe sounds really dirty for some reason. I'm sure most of PyTorch users are already familiar with Datasets, it is a convenient way to load data into our devices for training a batch eachn time. We can also do some preprocessing on the fly, which is very useful when we have a large dataset and we don't want to load all the data into memory at once.\n",
    "\n",
    "This is how a [pipe](https://pytorch.org/data/main/torchdata.datapipes.iter.html) comes in handy. Instead of loading the entire dataset into memory and then split into batches, we can import the data from a cloud bucket, one batch at a time;. This was also why we split our data into multiple files in the previous chapter.and we can also do some preprocessing on the fly. This is very useful when we have a large dataset and we don't want to load all the data into memory at once.\n",
    "\n",
    "With this, we can also easily perform data parallel training, which is a very useful technique when we have a large dataset and we want to train our model faster. Well I really hope you are excited about this because it is actually really really cool. Are you psyched? Did you have your hopes up? Well, too bad, we are not doing that here. Well, do I look like someone who can afford a machine with multiple GPUs?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall the dataframe**\n",
    ">\n",
    "    RangeIndex: 19454 entries, 0 to 19453\n",
    "    Data columns (total 22 columns):\n",
    "    #   Column           Non-Null Count  Dtype \n",
    "    ---  ------           --------------  ----- \n",
    "    0   headlines        19454 non-null  object\n",
    "    1   length           19454 non-null  int64 \n",
    "    2   has_num          19454 non-null  bool  \n",
    "    3   ner_percent      19454 non-null  int64 \n",
    "    4   ner_quantity     19454 non-null  int64 \n",
    "    5   ner_law          19454 non-null  int64 \n",
    "    6   ner_person       19454 non-null  int64 \n",
    "    7   ner_product      19454 non-null  int64 \n",
    "    8   ner_gpe          19454 non-null  int64 \n",
    "    9   ner_work_of_art  19454 non-null  int64 \n",
    "    10  ner_date         19454 non-null  int64 \n",
    "    11  ner_time         19454 non-null  int64 \n",
    "    12  ner_cardinal     19454 non-null  int64 \n",
    "    13  ner_org          19454 non-null  int64 \n",
    "    14  ner_money        19454 non-null  int64 \n",
    "    15  ner_language     19454 non-null  int64 \n",
    "    16  ner_ordinal      19454 non-null  int64 \n",
    "    17  ner_event        19454 non-null  int64 \n",
    "    18  ner_loc          19454 non-null  int64 \n",
    "    19  ner_fac          19454 non-null  int64 \n",
    "    20  ner_norp         19454 non-null  int64 \n",
    "    21  outcome          19454 non-null  int64 \n",
    "    dtypes: bool(1), int64(20), object(1)\n",
    "    memory usage: 3.1+ MB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, let do something fun by combining a pretrained model with some layers of our own. One of the most popular pretrained NLP is BERT, just like our favorite yellow muppet living in the basement apartment on *123 Sesame Street*. While the muppet Bert teaches you words and shit, the pretrained BERT embeds them. We can throw our entire text into BERT and we will get some sweet sweet embeddings. \n",
    "\n",
    "To do so, we need to tokenize the text, pretty much the same way you would process for a pre-transformer era NLP model. For that, we can use the BERT autotokenizer from HuggingFace.\n",
    "\n",
    "Now back to the data pipe, we first load data from S3 using PyTorch's inbuilt [S3FileLoader](https://pytorch.org/data/main/generated/torchdata.datapipes.iter.S3FileLoader.html), and then we\n",
    "    1. tokenize the news headlines into.. well, tokens padded to a length of 100, together with the attention masks. \n",
    "    2. convert the non-text features into tensors\n",
    "    3. return the `outcome` column as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(IterDataPipe):\n",
    "    '''\n",
    "    This class is used to load the data from S3 and return the data in the format of (bert_input, tabular_input, label)\n",
    "\n",
    "    Args:\n",
    "        s3_data_path: the url of the  directory containing the all the csv files in s3 \n",
    "        tokenizer: the tokenizer used to tokenize the text\n",
    "        num_files: the number of files to be loaded from s3\n",
    "    ''' \n",
    "    def __init__(self, s3_data_path: str, tokenizer: AutoTokenizer, num_files: int) -> None:\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.url_wrapper = IterableWrapper([s3_data_path]).list_files_by_s3().shuffle().sharding_filter()\n",
    "        self.num_files = num_files\n",
    "\n",
    "    def __iter__(self) -> tuple[torch.TensorType, ...]:\n",
    "        '''\n",
    "            This function defines the iterative behavior of the data pipe, which allows the __next__ method to get the next batch of data samples\n",
    "\n",
    "            Yields:\n",
    "                bert_input (torch.TensorType): the input of the BERT model, which is a list of two tensors, the first tensor is the input_ids, the second tensor is the attention_mask\n",
    "                tabular_input (torch.TensorType): the input of the tabular model, which is a list of tensors\n",
    "                label (torch.TensorType): the label of the data sample \n",
    "        '''\n",
    "        for _, file in self.url_wrapper.load_files_by_s3():\n",
    "            temp = pd.read_csv(file)\n",
    "            label = torch.from_numpy(temp['outcome'].values)\n",
    "            # For BERT model\n",
    "            bert_input = []\n",
    "            tokens = [self.tokenizer(t, padding='max_length', max_length=100, truncation=True, return_tensors='pt') for t in temp['headlines']]\n",
    "            bert_input.append(torch.cat([e['input_ids'] for e in tokens], dim=0))\n",
    "            bert_input.append(torch.cat([e['attention_mask'] for e in tokens], dim=0))\n",
    "\n",
    "            # Tabular features\n",
    "            tabular_input = [torch.from_numpy(temp[col].values).to(torch.float32).squeeze() for col in temp.columns if col not in ['outcome', 'headlines']]\n",
    "            yield bert_input, tabular_input, label\n",
    "\n",
    "    def __len__(self):\n",
    "        ''' \n",
    "            Returns the number of files to be loaded from s3, this method helps tqdm to know the progress of the data loading process.\n",
    "\n",
    "            Returns:\n",
    "                num_files (int): the number of files to be loaded from s3\n",
    "        '''\n",
    "        return self.num_files\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get to the part where people gets unnecessarily excited about: making the model. The model I had in mind kinda looks like this:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/model_architecture.png \"Model Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class FakeNewsClassifier(torch.nn.Module):\n",
    "    ''' \n",
    "        This class defines the model architecture of the fake news classifier, which is a combination of BERT model and tabular model.\n",
    "\n",
    "        Args:\n",
    "            pretrained_model_name: the name of the pretrained BERT model\n",
    "\n",
    "        Attributes:\n",
    "            bert: the pretrained BERT model\n",
    "            dropout_1: the dropout layer\n",
    "            linear: the linear layer with input shape equals to BERT embedding\n",
    "            dropout_2: the dropout layer\n",
    "            final_linear: the linear layer with input shape equals to the output shape of the tabular model\n",
    "            relu: the relu activation function\n",
    "            normalize: the normalization function\n",
    "            sigmoid: the sigmoid activation function  \n",
    "    '''\n",
    "    def __init__(self, pretrained_model_name: str) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.dropout_1 = torch.nn.Dropout(0.25)\n",
    "        self.linear = torch.nn.Linear(768, 12)\n",
    "        self.dropout_2 = torch.nn.Dropout(0.25)\n",
    "        self.final_linear = torch.nn.Linear(32, 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.normalize = torch.nn.functional.normalize\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, bert_input: dict, tabular_input: list):\n",
    "        ''' \n",
    "            This function defines the forward pass of the model, which takes the input of the BERT model and the tabular model, and returns the output of the model.\n",
    "\n",
    "            Args:\n",
    "                bert_input (dict): the input of the BERT model, which is a dictionary containing two tensors, the first tensor is the input_ids, the second tensor is the attention_mask, and a boolean parameter for return_dict\n",
    "                tabular_input (torch.TensorType): tensor for the input of the tabular model\n",
    "\n",
    "            Returns:\n",
    "                final_output (torch.TensorType): the output of the model, a single bit logit\n",
    "        '''\n",
    "        print(bert_input['input_ids'].shape, bert_input['attention_mask'].shape, tabular_input.shape)\n",
    "        # Left input path\n",
    "        _, pooled_output = self.bert(**bert_input)\n",
    "        dropout_1_output = self.dropout_1(pooled_output)\n",
    "        linear_output = self.linear(dropout_1_output)\n",
    "        relu_output = self.relu(linear_output)\n",
    "        norm1 = self.normalize(relu_output, p=2, dim=1)\n",
    "        \n",
    "        # Right input path\n",
    "        norm2 = self.normalize(tabular_input, p=2, dim=1)\n",
    "        # Combine two paths\n",
    "        combined_output = torch.cat([norm1, norm2], dim=1)\n",
    "        dropout_2_output = self.dropout_2(combined_output)\n",
    "        final_output = self.final_linear(dropout_2_output)\n",
    "        return self.sigmoid(final_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pretrained_model_name: str, train_data_url: str, test_data_url: str, train_len: int, test_len:int, train_file_len: int, test_file_len: int, epochs: int, lr: float):\n",
    "    # Prepare dataloaders\n",
    "    model = FakeNewsClassifier(pretrained_model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "\n",
    "    train_df = TextDataset(train_data_url, tokenizer, train_file_len)\n",
    "    test_df = TextDataset(test_data_url, tokenizer, test_file_len)\n",
    "\n",
    "    train_loader = DataLoader(train_df, batch_size=1, shuffle=True)\n",
    "    test_loader = DataLoader(test_df, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Config device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Config optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = torch.nn.BCELoss()\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        training_acc = 0.0\n",
    "\n",
    "        for bert_input, tabular_input, label in tqdm(train_loader):\n",
    "            bert_input = {\n",
    "                'input_ids': bert_input[0].squeeze().to(device),\n",
    "                'attention_mask': bert_input[1].squeeze().to(device),\n",
    "                'return_dict': False\n",
    "            }\n",
    "            tabular_input = torch.cat(tabular_input).T.to(device)\n",
    "            label = label.T.to(device)\n",
    "\n",
    "            output = model(bert_input, tabular_input)\n",
    "\n",
    "            loss = loss_function(output, label.float())\n",
    "            training_loss += loss.item()\n",
    "\n",
    "            # get acc of signmoid output\n",
    "            acc = (output[0].round() == label).sum().item()\n",
    "            training_acc += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        validation_loss = 0.0\n",
    "        validation_acc = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for bert_input, tabular_input, label in test_loader:\n",
    "                bert_input = {\n",
    "                    'input_ids': bert_input[0].squeeze().to(device),\n",
    "                    'attention_mask': bert_input[1].squeeze().to(device),\n",
    "                    'return_dict': False\n",
    "                }\n",
    "                tabular_input = torch.cat(tabular_input).T.to(device)\n",
    "                label = label.T.to(device)\n",
    "\n",
    "                output = model(bert_input, tabular_input)\n",
    "\n",
    "                loss = loss_function(output, label.float())\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                # get acc of signmoid output\n",
    "                acc = (output[0].round() == label).sum().item()\n",
    "                validation_acc += acc\n",
    "        print(f'Epoch: {epoch+1}/{epochs} | Training loss: {training_loss/train_len:.3f} | Training acc: {training_acc/train_len:.3f} | Validation loss: {validation_loss/test_len:.3f} | Validation acc: {validation_acc/test_len:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 973/973 [03:28<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1 | Training loss: 0.038 | Training acc: 0.871 | Validation loss: 0.038 | Validation acc: 0.883\n",
      "Model saved to:   assets/model\n"
     ]
    }
   ],
   "source": [
    "pretrain_name = 'bert-base-uncased'\n",
    "model = FakeNewsClassifier(pretrain_name)\n",
    "EPOCHS = 1\n",
    "LR = 5e-6\n",
    "\n",
    "train_model(\n",
    "    pretrain_name, \n",
    "    TRAIN_S3_URL, \n",
    "    TEST_S3_URL, \n",
    "    TRAIN_DATASET_SIZE, \n",
    "    TEST_DATASET_SIZE, \n",
    "    TRAIN_FILES, \n",
    "    TEST_FILES,\n",
    "    EPOCHS, \n",
    "    LR\n",
    ")\n",
    "\n",
    "import os\n",
    "if not os.path.exists(MODEL_OUTPUT_PATH):\n",
    "    os.makedirs(MODEL_OUTPUT_PATH)\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_OUTPUT_PATH + '/baseline.pth')\n",
    "print('Model saved to:  ', MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer\n",
    "pretrain_name = 'bert-base-uncased'\n",
    "# load model from output path\n",
    "model = FakeNewsClassifier(pretrain_name)\n",
    "model.load_state_dict(torch.load(MODEL_OUTPUT_PATH + '/baseline.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure F1 score from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244/244 [03:42<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8316017316017316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# tokenizer = AutoTokenizer.from_pretrained(pretrain_name)\n",
    "# test_ds = TextDataset(TEST_S3_URL, tokenizer, TEST_FILES)\n",
    "# test_loader = DataLoader(test_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = []\n",
    "#     labels = []\n",
    "#     for bert_input, tabular_input, label in tqdm(test_loader):\n",
    "#         bert_input = {\n",
    "#             'input_ids': bert_input[0].squeeze(),\n",
    "#             'attention_mask': bert_input[1].squeeze(),\n",
    "#             'return_dict': False\n",
    "#         }\n",
    "#         tabular_input = torch.cat(tabular_input).T\n",
    "#         label = label.T\n",
    "\n",
    "#         outputs.append(model(bert_input, tabular_input))\n",
    "#         labels.append(label)\n",
    "\n",
    "# output = torch.cat(outputs, dim=0)\n",
    "# label = torch.cat(labels, dim=0)\n",
    "# print(f'F1 score: {f1_score(output.round().detach().numpy(), label.detach().numpy())}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make inference with model and user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrain_name)\n",
    "\n",
    "def preprocess_headline(headline: str):\n",
    "    tokens = tokenizer(headline, return_tensors='pt', padding='max_length', truncation=True, max_length=64)\n",
    "    tokens = {k: v.squeeze() for k, v in tokens.items()}\n",
    "    input_ids = tokens['input_ids'].unsqueeze(0)\n",
    "    attention_mask = tokens['attention_mask'].unsqueeze(0)\n",
    "    bert_input = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'return_dict': False\n",
    "    }\n",
    "\n",
    "\n",
    "    headline_len = len(headline.split())\n",
    "    has_stats = int(re.match(r'\\d', headline) is not None)\n",
    "\n",
    "    ner_count = [f'ner_{ent.label_}' for ent in nlp(headline).ents]\n",
    "    ner_count = Counter(ner_count)\n",
    "    ner_input = get_ner_input(ner_count, input_schema)\n",
    "    return bert_input, torch.cat([torch.tensor([headline_len, has_stats]), ner_input], dim=0).unsqueeze(0)\n",
    "\n",
    "    \n",
    "def get_ner_input(ner_count, input_schema):\n",
    "    ner_features = [s for s in input_schema if s.startswith('ner_')]\n",
    "    ner_input = torch.zeros(len(ner_features))\n",
    "    for i, feat in enumerate(ner_features):\n",
    "        ner_input[i] = ner_count.get(feat, 0)\n",
    "    return ner_input\n",
    "    \n",
    "\n",
    "def classify(headline: str):\n",
    "    bert_input, tabular_input = preprocess_headline(headline)\n",
    "    with torch.no_grad():\n",
    "        output = model(bert_input, tabular_input)\n",
    "    return output.round().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6336e33fd1414fa18b03edf42f842cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Headline:', layout=Layout(display='flex', flex_flow='column wrap', height='69p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c3c73b945941db9de95b1332a0c3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Button(description='Fact Check', layout=Layout(display='flex'), style=ButtonStyle()), Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# notebook text input ui\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "\n",
    "text = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='Headline:',\n",
    "    disabled=False,\n",
    "    layout={'width': '69%', 'height': '69px', 'display': 'flex', 'flex_flow': 'column wrap'}\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Fact Check\", layout={'display': 'flex'})\n",
    "out = widgets.Label(value='Click button to fact check headline!', layout={'display': 'flex', 'flex_flow': 'column wrap', 'align_items': 'flex-end'})\n",
    "\n",
    "def fact_check(b):\n",
    "    headline = text.value\n",
    "    pred = classify(headline)\n",
    "    \n",
    "    if pred == 1:\n",
    "        \n",
    "        out.value = 'This is fake news!'\n",
    "    else:\n",
    "        out.value = 'This is real news!'\n",
    "\n",
    "button.on_click(fact_check)\n",
    "\n",
    "vb = widgets.Box([button, out])\n",
    "display(text)\n",
    "display(vb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
